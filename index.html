<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <title>ROCLING 2025</title>
  <meta content="width=device-width, initial-scale=1.0" name="viewport">
  <meta content="" name="keywords">
  <meta content="" name="description">

  <!-- Favicons -->
  <link href="img/favicon_io/favicon-32x32.png" rel="icon">
  <link href="img/favicon_io/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,700,700i|Raleway:300,400,500,700,800" rel="stylesheet">

  <!-- Bootstrap CSS File -->
  <link href="lib/bootstrap/css/bootstrap.min.css" rel="stylesheet">

  <!-- Libraries CSS Files -->
  <link href="lib/font-awesome/css/font-awesome.min.css" rel="stylesheet">
  <link href="lib/animate/animate.min.css" rel="stylesheet">
  <link href="lib/venobox/venobox.css" rel="stylesheet">
  <link href="lib/owlcarousel/assets/owl.carousel.min.css" rel="stylesheet">

  <!-- Main Stylesheet File -->
  <link href="css/style.css?1" rel="stylesheet">

  <!-- Google Search Console -->
  <meta name="google-site-verification" content="-fD59RiHc4OQb37XpVtmZkcUeguaxVbKsDHtu6wsbQo" />
  
  <!-- =======================================================
    Theme Name: TheEvent
    Theme URL: https://bootstrapmade.com/theevent-conference-event-bootstrap-template/
    Author: BootstrapMade.com
    License: https://bootstrapmade.com/license/
  ======================================================= -->
</head>

<body>
  <!--==========================
    Header
  ============================-->
  <header id="header" tpl="header">
    <data hidden>
    { "logoText": "ROCLING 2025" }
  </data>
  </header><!-- #header -->

  <!--==========================
    Intro Section
  ============================-->
  <section id="intro" tpl="intro"></section>

  <main id="main">

    <!--==========================
      About Section
    ============================-->
    <section id="about" tpl="about"></section>

    <!--==========================
      Important Dates Section
    ============================-->
    <section id="dates" tpl="dates"  class="wow fadeInUp"></section>


    <!--==========================
      Call For Paper Section
    ============================-->
    <section id="call" tpl="call"  class="section-with-bg fadeInUp"></section>

    <!--==========================
      Speakers Introduction Section
    ============================-->
    <section id="speakers" tpl="speakers" class="wow fadeInUp">
	    <data hidden>
{
  "Tutorial" :[
    {
      "title": "Tutorial I: AI-Driven Hearing Assistive Technologies: From Algorithm Innovation to Regulatory Readiness",
      "speaker": {
        "name": "Prof. Ying-Hui Lai",
        "affiliation": "Department of Biomedical Engineering, National Yang Ming Chiao Tung University",
        "link": "https://sites.google.com/view/yinghu-lai/"
      },
      "img": "img/speakers/Ying-Hui_Lai.png",
      "abstract": ["Speech is one of the most efficient forms of human communication. However, when auditory and articulation systems are compromised by conditions like sensorineural hearing loss, this ability is significantly impacted. While hearing assistive technologies, such as modern over-the-counter hearing aids (OTC HA), offer essential support, their real-world performance, particularly in complex acoustic environments and during the fitting process, presents significant challenges, limiting the full potential for improved communication.", "Addressing these limitations, this tutorial explores the AI-driven design and implementation of next-generssation hearing assistive technologies, demonstrating the journey from Algorithm Innovation to Regulatory Readiness. We will demonstrate how leveraging advanced Artificial Intelligence techniques can revolutionize the core signal processing and fitting procedures within these devices.", "Specifically, we will delve into the application of AI in three critical areas that underpin the next generation of personalized hearing care: (1) App-based hearing tests utilizing Active Noise Cancellation (ANC) technology to provide accurate and accessible initial hearing evaluations, (2) AI algorithms for enhancing “face-to-face” perception to significantly improve speech intelligibility in noisy conditions and (3) Precision Fitting Technology to alleviate the individual ear canal differences by the proposed RehearFit technology.", "Crucially, all presented methods are supported by clinical validation results, demonstrating quantifiable efficacy. Furthermore, given that these AI components often qualify the devices as Smart Medical Devices, the tutorial will also introduce essential regulatory considerations for AI/ML-based medical software. This section will guide attendees on how to strategically plan for the iterative development and deployment of AI/ML models post-market while maintaining compliance and ensuring safety and effectiveness.", "This tutorial demonstrates that integrating these AI-driven approaches into future hearing assistive devices holds significant potential to enhance overall user experience, communication effectiveness, and the efficiency of clinical workflows, setting the stage for both technological innovation and successful productization."]
    },
    {
      "title": "Tutorial II: Hearing through Light: Deep Learning and Optical Microphones for Robust Speech Reconstruction and Audio Intelligence",
      "speaker": {
        "name": "Prof. Ying-Hui Lai",
        "affiliation": "Department of Biomedical Engineering, National Yang Ming Chiao Tung University",
        "link": "https://sites.google.com/view/yinghu-lai/"
      },
      "abstract": ["The fundamental physics of sound is vibration. Any speech is a physical manifestation of source vibration in the air. Therefore, if the signal from the vibration source can be accurately captured, there is a distinct opportunity to reconstruct high-fidelity audio. This principle is particularly vital in challenging acoustic environments where conventional air-conducted microphones fail due to ambient noise interference and signal decay over distance.", "To realize robust audio acquisition under these challenging conditions, this tutorial introduces the paradigm of \"Hearing through Light\", utilizing the novel Straw of Sound (SoS) Technology—a non-contact speech sensing system that integrates Laser Doppler Vibrometer (LDV) sensing with Deep Learning (DL). The core innovation lies in acquiring micro-vibrations from nearby objects (e.g., a medical mask or ambient surfaces) induced by speech, thus bypassing the conventional, noise-susceptible acoustic pathway.", "Building upon this innovation, this tutorial will detail the entire framework of the SoS Technology, covering the Optical Sensing Principle, the proposed SoS System Concept, and various Vocational Applications such as enhancing hearing assistive devices, utilizing optical-based dysarthria voice conversion (LDVC), and performing pathological voice detection. Furthermore, we will explore Audio Intelligence applications, including retrieving directional sound information and stereo synthesis from single-point vibration data, followed by strategies for Micro-Hardware Realization and system miniaturization.", "This tutorial establishes that \"Hearing through Light\" is a viable and robust methodology that transforms the fundamental principle of sound into superior audio acquisition, setting the stage for the next generation of personalized audio and communication intelligence."]
    },
    {
      "description": "Dr. Ying-Hui Lai is a Professor and Chair of Biomedical Engineering at National Yang Ming Chiao Tung University. His research interests include hearing and communication assistive devices, speech and bio-signal processing, optical microphones, and AI applications. Since earning his Ph.D. in 2013, he has authored over 100 papers and secured ten patents, leading to recent implementations on Bluetooth audio chips for wireless earbuds and hearing aids. A recipient of the 2023 FutureTech Award, the National Innovation Award, and a Gold Medal at the Global Student Innovation Challenge (gSIC), his work has been consistently recognized for its innovation. His research on optical microphones was also notably highlighted by the American Institute of Physics in AIP Scilight."
    }
  ],
  "Keynote" :[
    {
      "title": "Keynote I: Towards Social Agents",
      "speaker": {
        "name": "Asli Celikyilmaz",
        "affiliation": "Meta FAIR",
        "link": "http://asli.us/"
      },
      "img": "img/keynote/Celikyilmaz.png",
      "description": "Asli Celikyilmaz is a Senior Research Manager at Fundmendals AI Research (FAIR). Formerly, she was Senior Principal Researcher at Microsoft Research (MSR) in Redmond, Washington. She is also an Affiliate Associate Member at the University of Washington. She has received Ph.D. Degree in Information Science from University of Toronto, Canada, and later continued her Postdoc study at Computer Science Department of the University of California, Berkeley. Her research interests are mainly in deep learning and natural language, specifically on language generation with long-term coherence, language understanding, language grounding with vision, and building intelligent agents for human-computer interaction She is serving on the editorial boards of Transactions of the ACL (TACL) as area editor and Open Journal of Signal Processing (OJSP) as Associate Editor. She has received several “best of” awards including NAFIPS 2007, Semantic Computing 2009, CVPR 2019, EMNLP 2023.",
      "abstract": "As language models evolve into social agents, new challenges arise around reasoning, collaboration, and understanding others' minds. I'll share three directions that move us beyond next-word prediction and towards social agents: collaborative reasoning, where agents learn to communicate, coordinate, and build on each other's ideas; mental modeling (theory of mind), the ability to represent what others know, believe, or intend; and social preference alignment, where models learn human values not just from isolated feedback but through extended, context-rich interaction. Together, these efforts aim to build agents that not only converse fluently but also reason jointly, interpret intentions, and evolve toward more adaptive, long-horizon social intelligence."
    },
    {
      "title": "Keynote II: Giving Voice and Face to AI",
      "speaker": {
        "name": "Joon Son Chung",
        "affiliation": "KAIST",
        "link": "https://mm.kaist.ac.kr/joon/"
      },
      "img": "img/keynote/Chung.png",
      "description": "Joon Son Chung is an associate professor at the School of Electrical Engineering, KAIST, where he is directing the Multimodal AI Lab. Previously, he was a research team lead at Naver Corporation, where he managed the development of speech recognition models for various applications including Clova Note and LINE CLOVA AI Speaker. He received his BA and PhD from the University of Oxford, working with Prof. Andrew Zisserman. His work has been published in top-tier venues such as TPAMI and IJCV, and he has received several paper awards, including at Interspeech and ACCV. His research interests include speaker recognition, multimodal learning, visual speech synthesis and audio-visual speech recognition. He is a co-author of the well-known audio-visual dataset for human speech, VoxCeleb. According to Google Scholar, his work has accumulated over 17,000 citations.",
      "abstract": ["As AI systems advance, building natural and intuitive multimodal interfaces is becoming increasingly critical. This talk examines technologies that equip AI with both a voice and a face, improving their capacity for seamless, expressive communication with humans.", "We will discuss how incorporating visual and linguistic signals into speech synthesis enables alignment between acoustic output, facial and textual attributes, yielding more natural and expressive speech generation. Our recent work synthesises speech directly from visual inputs, enabling communication where audio signals are limited or absent. In parallel, we present our talking head synthesis system, where audio inputs generate lifelike facial animations, effectively giving a face to the AI's voice and enriching the multimodal interaction."]
    }
  ]
}
	    </data>
    </section>
    <!--==========================
      Schedule Section
    ============================-->
    <section id="schedule" tpl="schedule" class="wow fadeInUp">
	    <data hidden>
{
  "days": [
    {
      "title": "Day 1 (Thursday), November 20, 2025",
      "periods": [
        {
          "time": "13:30 - 14:00",
          "sessions": [
            {
              "title": "Registration",
              "location": "2F, space M Lobby"
            }
          ]
        },
        {
          "time": "14:00 - 15:30",
          "sessions": [
            {
              "title": "Tutorial",
              "location": "2F, space M Session Room",
              "speaker": {
                "name": "Prof. Ying-Hui Lai",
                "affiliation": "Department of Biomedical Engineering, National Yang Ming Chiao Tung University",
                "bio": "Dr. Ying-Hui Lai is a Professor and Chair of Biomedical Engineering at National Yang Ming Chiao Tung University. His research interests include hearing and communication assistive devices, speech and bio-signal processing, optical microphones, and AI applications. Since earning his Ph.D. in 2013, he has authored over 100 papers and secured ten patents, leading to recent implementations on Bluetooth audio chips for wireless earbuds and hearing aids. A recipient of the 2023 FutureTech Award, the National Innovation Award, and a Gold Medal at the Global Student Innovation Challenge (gSIC), his work has been consistently recognized for its innovation. His research on optical microphones was also notably highlighted by the American Institute of Physics in AIP Scilight."
              },
              "image": "img/speakers/Ying-Hui_Lai.png",
              "subject": "AI-Driven Hearing Assistive Technologies: From Algorithm Innovation to Regulatory Readiness",
              "abstract": ["Speech is one of the most efficient forms of human communication. However, when auditory and articulation systems are compromised by conditions like sensorineural hearing loss, this ability is significantly impacted. While hearing assistive technologies, such as modern over-the-counter hearing aids (OTC HA), offer essential support, their real-world performance, particularly in complex acoustic environments and during the fitting process, presents significant challenges, limiting the full potential for improved communication.", "Addressing these limitations, this tutorial explores the AI-driven design and implementation of next-generssation hearing assistive technologies, demonstrating the journey from Algorithm Innovation to Regulatory Readiness. We will demonstrate how leveraging advanced Artificial Intelligence techniques can revolutionize the core signal processing and fitting procedures within these devices.", "Specifically, we will delve into the application of AI in three critical areas that underpin the next generation of personalized hearing care: (1) App-based hearing tests utilizing Active Noise Cancellation (ANC) technology to provide accurate and accessible initial hearing evaluations, (2) AI algorithms for enhancing “face-to-face” perception to significantly improve speech intelligibility in noisy conditions and (3) Precision Fitting Technology to alleviate the individual ear canal differences by the proposed RehearFit technology.", "Crucially, all presented methods are supported by clinical validation results, demonstrating quantifiable efficacy. Furthermore, given that these AI components often qualify the devices as Smart Medical Devices, the tutorial will also introduce essential regulatory considerations for AI/ML-based medical software. This section will guide attendees on how to strategically plan for the iterative development and deployment of AI/ML models post-market while maintaining compliance and ensuring safety and effectiveness.", "This tutorial demonstrates that integrating these AI-driven approaches into future hearing assistive devices holds significant potential to enhance overall user experience, communication effectiveness, and the efficiency of clinical workflows, setting the stage for both technological innovation and successful productization."]
            }
          ]
        },
        {
          "time": "15:30 - 15:50",
          "sessions": [
            {
              "title": "Coffee Break",
              "location": "2F, space M Lobby"
            }
          ]
        },
        {
          "time": "15:50 - 17:20",
          "sessions": [
            {
              "title": "Tutorial",
              "location": "2F, space M Session Room",
              "speaker": {
                "name": "Prof. Ying-Hui Lai",
                "affiliation": "Department of Biomedical Engineering, National Yang Ming Chiao Tung University",
                "bio": "Dr. Ying-Hui Lai is a Professor and Chair of Biomedical Engineering at National Yang Ming Chiao Tung University. His research interests include hearing and communication assistive devices, speech and bio-signal processing, optical microphones, and AI applications. Since earning his Ph.D. in 2013, he has authored over 100 papers and secured ten patents, leading to recent implementations on Bluetooth audio chips for wireless earbuds and hearing aids. A recipient of the 2023 FutureTech Award, the National Innovation Award, and a Gold Medal at the Global Student Innovation Challenge (gSIC), his work has been consistently recognized for its innovation. His research on optical microphones was also notably highlighted by the American Institute of Physics in AIP Scilight."
              },
              "image": "img/speakers/Ying-Hui_Lai.png",
              "subject": "Hearing through Light: Deep Learning and Optical Microphones for Robust Speech Reconstruction and Audio Intelligence",
              "abstract": ["The fundamental physics of sound is vibration. Any speech is a physical manifestation of source vibration in the air. Therefore, if the signal from the vibration source can be accurately captured, there is a distinct opportunity to reconstruct high-fidelity audio. This principle is particularly vital in challenging acoustic environments where conventional air-conducted microphones fail due to ambient noise interference and signal decay over distance.", "To realize robust audio acquisition under these challenging conditions, this tutorial introduces the paradigm of \"Hearing through Light\", utilizing the novel Straw of Sound (SoS) Technology—a non-contact speech sensing system that integrates Laser Doppler Vibrometer (LDV) sensing with Deep Learning (DL). The core innovation lies in acquiring micro-vibrations from nearby objects (e.g., a medical mask or ambient surfaces) induced by speech, thus bypassing the conventional, noise-susceptible acoustic pathway.", "Building upon this innovation, this tutorial will detail the entire framework of the SoS Technology, covering the Optical Sensing Principle, the proposed SoS System Concept, and various Vocational Applications such as enhancing hearing assistive devices, utilizing optical-based dysarthria voice conversion (LDVC), and performing pathological voice detection. Furthermore, we will explore Audio Intelligence applications, including retrieving directional sound information and stereo synthesis from single-point vibration data, followed by strategies for Micro-Hardware Realization and system miniaturization.", "This tutorial establishes that \"Hearing through Light\" is a viable and robust methodology that transforms the fundamental principle of sound into superior audio acquisition, setting the stage for the next generation of personalized audio and communication intelligence."]
            }
          ]
        }
      ]
    },
    {
      "title": "Day 2 (Friday), November 21, 2025",
      "periods": [
        {
          "time": "08:30 - 08:50",
          "sessions": [
            {
              "title": "Registration",
              "location": "2F, space M Lobby"
            }
          ]
        },
        {
          "time": "08:50 - 09:10",
          "sessions": [
            {
              "title": "Opening Ceremony",
              "location": "2F, space M Session Room"
            }
          ]
        },
        {
          "time": "09:10 - 10:10",
          "sessions": [
            {
              "title": "Keynote I",
              "location": "2F, space M Session Room/ 1F, R117",
              "speaker": {
                "name": "Asli Celikyilmaz",
                "affiliation": "Meta FAIR",
                "bio": "Asli Celikyilmaz is a Senior Research Manager at Fundmendals AI Research (FAIR). Formerly, she was Senior Principal Researcher at Microsoft Research (MSR) in Redmond, Washington. She is also an Affiliate Associate Member at the University of Washington. She has received Ph.D. Degree in Information Science from University of Toronto, Canada, and later continued her Postdoc study at Computer Science Department of the University of California, Berkeley. Her research interests are mainly in deep learning and natural language, specifically on language generation with long-term coherence, language understanding, language grounding with vision, and building intelligent agents for human-computer interaction She is serving on the editorial boards of Transactions of the ACL (TACL) as area editor and Open Journal of Signal Processing (OJSP) as Associate Editor. She has received several “best of” awards including NAFIPS 2007, Semantic Computing 2009, CVPR 2019, EMNLP 2023."
              },
              "image": "img/keynote/Celikyilmaz.png",
              "subject": "Towards Social Agents",
              "abstract": "As language models evolve into social agents, new challenges arise around reasoning, collaboration, and understanding others' minds. I'll share three directions that move us beyond next-word prediction and towards social agents: collaborative reasoning, where agents learn to communicate, coordinate, and build on each other's ideas; mental modeling (theory of mind), the ability to represent what others know, believe, or intend; and social preference alignment, where models learn human values not just from isolated feedback but through extended, context-rich interaction. Together, these efforts aim to build agents that not only converse fluently but also reason jointly, interpret intentions, and evolve toward more adaptive, long-horizon social intelligence."
            }
          ]
        },
        {
          "time": "10:10 - 10:30",
          "sessions": [
            {
              "title": "Coffee Break",
              "location": "2F, space M Lobby"
            }
          ]
        },
        {
          "time": "10:30 - 12:00",
          "sessions": [
            {
              "title": "Oral I",
              "location": "2F, space M Session Room",
              "chair": "蘇明祥",
              "talks": [
                {
                  "title":"CLiFT-ASR: A Cross-Lingual Fine-Tuning Framework for Low-Resource Taiwanese Hokkien Speech Recognition (#37)",
                  "author":"Hung-Yang Sung, Chien-Chun Wang, Kuan-Tang Huang, Tien-Hong Lo, Yu-Sheng Tsao, Yung-Chang Hsu and Berlin Chen"
                },
                {
                  "title":"Memory-Efficient Training for Text-Dependent SV with Independent Pre-trained Models (#20)",
                  "author":"Seyed Ali Farokh and Hossein Zeinali"
                },
                {
                  "title":"Diversity is the Key: Enhancing LLM-based Post-processing for Automated Audio Captioning (#19)",
                  "author":"Seyed Ali Farokh, Mohammad Mehdi Homayounpour and Ahmad Nickabadi"
                },
                {
                  "title":"A Multi-faceted Statistical Analysis for Logit-based Pronunciation Assessment (#59)",
                  "author":"Chieh-Ren Liao and Berlin Chen"
                },
                {
                  "title":"Constructing a Voice-Driven Command System for Chinese ASR Error Correction (#51)",
                  "author":"Sji-Jie Ding, Chia-Hui Chang and Zi-Xuan Jian"
                },
                {
                  "title":"Design and Evaluation of a Courtroom Examination AI Simulation System with Behavioral Fidelity (#4)",
                  "author":"Hsienjyh Liao"
                }
              ]
            },
            {
              "title": "Oral II",
              "location": "1F, R117",
              "chair": "陳信希",
              "talks":[
                {
                  "title":"Language Modeling Using Entanglement Enhanced Tensor Trains (#49)",
                  "author":"Ellis Reyes and Yi-Shin Chen"
                },
                {
                  "title":"Embodiment in Multimodal Semantics: Comparing Sensory, Emotional, and Visual Features in Chinese Color Metaphors (#46)",
                  "author":"Yufeng Wu and Meichun Liu"
                },
                {
                  "title":"From Scarcity to Scalability: Lexicon and Grammar Enhanced Amis to Mandarin Translation with GPT Models (#36)",
                  "author":"Joseph Lin, Kai-Ying Lin and Hung-Yu Kao"
                },
                {
                  "title":"大型語言模型結合評分規準於國小學生書籍摘要自動批改之可行性研究 (#35)",
                  "author":"Qi-Zhen Huang, Hou-Chiang Tseng and Yao-Ting Sung"
                },
                {
                  "title":"基於隱藏式馬可夫模型的中文熟語自動糾錯新方法 A Novel Chinese-Idiom Automatic Error Correction Method Based on the Hidden Markov Model (#25)",
                  "author":"Rongbin Zhang, Anlu Gui, Peng Cao, Lingfeng Wu, Feng Huang and Jiahui Li"
                },
                {
                  "title":"LOBSTER: Linguistics Olympiad Benchmark for Structured Evaluation on Reasoning (#42)",
                  "author":"Da-Chen Lian, Ri-Sheng Huang, Pin-Er Chen, Chunki Lim, You-Kuan Lin, Tzu-Cheng Yang, Zhen-Yu Lin, Pin-Cheng Chen and Shu-Kai Hsieh"
                }
              ]
            }
          ]
        },
        {
          "time": "12:00 - 13:00",
          "sessions": [
            {
              "title": "Lunch",
              "location": "1F, R117/ 1F, R118"
            }
          ]
        },
        {
          "time": "13:00 - 13:30",
          "sessions": [
            {
              "title": "ACLCLP Assembly",
              "location": "2F, space M Session Room"
            }
          ]
        },
        {
          "time": "13:30 - 15:30",
          "sessions": [
            {
              "title": "SS: FSR-2025",
              "location": "2F, space M Session Room",
              "talks": [
                {
                  "title":"Applying Whisper Fine-tuning and Branchformer to Hakka Speech Recognition (#27)",
                  "author":"Yu-Sheng Huang, Wei-Cheng Hong, Xin-Yu Chen and Szu-Yin Lin"
                },
                {
                  "title":"A Channel-Aware Anomaly-Guided Data Augmentation Framework for the FSR-2025 Hakka Speech Recognition Challenge (#73)",
                  "author":"Siang-Ting Lin, Arthur Hao, Chiun-Yu Hua, Kuan-Tang Huang and Berlin Chen"
                },
                {
                  "title":"An Empirical Study of Whisper on Low-Resource Hakka Speech Recognition: Practical Challenges and Failure Analysis (#75)",
                  "author":"Pei-Chi Lan, Hsin-Tien Chiang, Ting-Chun Lin and Ming-Hsiang Su"
                },
                {
                  "title":"The AS-SLAM system for Formosa Speech Recognition Challenge 2025 (#74)",
                  "author":"Chih-Hsi Chen, Pei-Jun Liao, Chia-Hua Wu, Pang Cheng Wu and Hsin-Min Wang"
                },
                {
                  "title":"多模組錯誤檢測與修正的客語語音辨識系統 (#71)",
                  "author":"Min-Chun Hu, Yu-Lin Xiao and Wen-Hsiang Lu"
                },
                {
                  "title":"Improving Low-Resource Speech Recognition with Whisper-MoE and Synthetic Data Augmentation: A Case Study on Hakka (#28)",
                  "author":"Yuan-Chi Hsu, Liang-Chun Fang and Hong-Jie Dai"
                }
              ]
            },
            {
              "title": "Round Table",
              "location": "5F, CSIE Maker Space",
              "note":[
                "session one: 13:30 - 14:25",
                "session two: 14:35 - 15:30"
              ]
            }
          ]
        },
        {
          "time": "15:30 - 15:50",
          "sessions": [
            {
              "title": "Coffee Break",
              "location": "2F, space M Lobby"
            }
          ]
        },
        {
          "time": "15:50 - 17:50",
          "sessions": [
            {
              "title": "SS: FSR-2025",
              "location": "2F, space M Session Room",
              "talks": [
              {
                  "title":"Whisper Finetuning For Hakka Recognition in Low Resource (#30)",
                  "author":"Ci Dao Chen, Min Han Teng, Bing Jhih Huang and You Ting Lin"
                },
                {
                  "title":"低資源語言的語音辨識：客語漢字與拼音模型比較 Speech Recognition for Low-resource Languages: A Comparative Study on Hakka Han Characters and Romanization (#13)",
                  "author":"宇翔 鄭 and 亦軒 吳"
                },
                {
                  "title":"A Study on a Low-Resource Speech Recognition System for Taiwan Hakka Based on Whisper and LoRA (#63)",
                  "author":"Zheng-Ting Liu, Heng-You Wang, Yi-Xiang Liao and Zhong-Yuan Qiu"
                },
                {
                  "title":"A Compact Whisper+LoRA Baseline for Taiwanese Hakka ASR in FSR-2025 (#68)",
                  "author":"Hung-Ting Hsieh"
                },
                {
                  "title":"A Whisper-Based System with Multi-Faceted Data Augmentation for Low-Resource Language (#72)",
                  "author":"Pin-Cheng Chen, Yu-Chi Chen, Chia-Chun Liang, Cheng-Yu Lin, Ping-Juei Tsai and Wei-Yun Ma"
                },
                {
                  "title":"Optimizing Whisper Parameters and Training Data Processing for Formosa Speech Recognition Challenge 2025 - Hakka ASR II (#69)",
                  "author":"Jhen-Hao Lee, Sheng-Wei Kuo, An-Che Cheng, Bing-Hua Chen and Yi-An Liu"
                },
                {
                  "title":"Hakka Speech Recognition with Whisper and Pinyin Post-processing for FSR-2025 (#58)",
                  "author":"Chia-Hsin Lee, Yung Jun Chang, Jin-Yan Wu and Kuan-Yu Chen"
                },
                {
                  "title":"The NPTU ASR System for FSR2025 Hakka Character/Pinyin Recognition: Whisper with mBART Post-Editing and RNNLM Rescoring (#76)",
                  "author":"Yi-Chin Huang, Yu-Heng Chen, Jian-Hua Wang and Hsiu-Chi Wu"
                },
                {
                  "title":"The EZ-AI System for Formosa Speech Recognition Challenge 2025 (#70)",
                  "author":"Yu-Sheng Tsao, Hung-Yang Sung, An-Ci Peng, Jhih-Rong Guo and Tien-Hong Lo"
                }
              ]
            },
            {
              "title": "SS: DSA-MST",
              "location": "1F, R117",
              "talks":[
                {
                  "title":"ROCLING-2025 Shared Task: Chinese Dimensional Sentiment Analysis for Medical Self-Reflection Texts (#65)",
                  "author":"Lung-Hao Lee, Tzu-Mi Lin Lin, Hsiu-Min Shih, Kuo-Kai Shyu, Anna S. Hsu and Peih-Ying Lu"
                },
                {
                  "title":"KOLab at ROCLING 2025 Dimensional Sentiment Analysis - Shared Task: Research on Emotional Dimensions in Chinese Medical Self-Reflection Texts (#66)",
                  "author":"Chia-Yu Chan, Chia-Wen Wang and Jui-Feng Yeh"
                },
                {
                  "title":"EmoTracer: Emotion-Space-Based System for Doctors' Self-Reflection Sentiment Analysis (#64)",
                  "author":"Ting-Yi Lin, Cong-Ying Lin and Jui-Feng Yeh"
                },
                {
                  "title":"SCUNLP at ROCLING-2025 Shared Task: Systematic  Guideline Refinement for Continuous Value Prediction  with Outlier-Driven LLM Feedback (#67)",
                  "author":"Hong Rui Pan and Jheng Long Wu"
                },
                {
                  "title":"TCU at ROCLING-2025 Shared Task: Leveraging LLM Embeddings and Ensemble Regression in Chinese Texts (#15)",
                  "author":"Hsin-Chieh Li and Wen-Cheng Lin"
                },
                {
                  "title":"NTULAW at ROCLING-2025 Shared Task (#12)",
                  "author":"Sieh-Chuen Huang and Hsuan-Lei Shao"
                },
                {
                  "title":"CYUT-NLP at ROCLING-2025 Shared Task: Valence-Arousal Prediction in Physicians' Texts Using BERT, RAG, and Multi-Teacher Pseudo-Labeling (#8)",
                  "author":"Yi-Min Jian, An Yu Hsiao and Shih-Hung Wu"
                }
              ]
            }
          ]
        },
        {
          "time": "17:50-20:30",
          "sessions": [
            {
              "title": "Banquet (Starts at 18:30)",
              "location": "MD or Just Italian"
            }
          ]
        }

      ]
    },
    {
      "title": "Day 3 (Saturday), November 22, 2025",
      "periods": [
        {
          "time": "08:50 - 09:10",
          "sessions": [
            {
              "title": "Registration",
              "location": "2F, space M Lobby"
            }
          ]
        },
        {
          "time": "09:10 - 10:10",
          "sessions": [
            {
              "title": "Keynote II",
              "location": "2F, space M Session Room/ 1F, R117",
              "speaker": {
                "name": "Joon Son Chung",
                "affiliation": "KAIST",
                "bio": "Joon Son Chung is an associate professor at the School of Electrical Engineering, KAIST, where he is directing the Multimodal AI Lab. Previously, he was a research team lead at Naver Corporation, where he managed the development of speech recognition models for various applications including Clova Note and LINE CLOVA AI Speaker. He received his BA and PhD from the University of Oxford, working with Prof. Andrew Zisserman. His work has been published in top-tier venues such as TPAMI and IJCV, and he has received several paper awards, including at Interspeech and ACCV. His research interests include speaker recognition, multimodal learning, visual speech synthesis and audio-visual speech recognition. He is a co-author of the well-known audio-visual dataset for human speech, VoxCeleb. According to Google Scholar, his work has accumulated over 17,000 citations."
              },
              "image": "img/keynote/Chung.png",
              "subject": "Giving Voice and Face to AI",
              "abstract": ["As AI systems advance, building natural and intuitive multimodal interfaces is becoming increasingly critical. This talk examines technologies that equip AI with both a voice and a face, improving their capacity for seamless, expressive communication with humans.", "We will discuss how incorporating visual and linguistic signals into speech synthesis enables alignment between acoustic output, facial and textual attributes, yielding more natural and expressive speech generation. Our recent work synthesises speech directly from visual inputs, enabling communication where audio signals are limited or absent. In parallel, we present our talking head synthesis system, where audio inputs generate lifelike facial animations, effectively giving a face to the AI's voice and enriching the multimodal interaction."]
            }
          ]
        },
        {
          "time": "10:10 - 10:30",
          "sessions": [
            {
              "title": "Coffee Break",
              "location": "2F, space M Lobby"
            }
          ]
        },
        {
          "time": "10:30 - 12:00",
          "sessions": [
            {
              "title": "SS: PLAAI",
              "location": "2F, space M Session Room",
              "talks": [
                {
                  "title":"Introduction: Persuasive Language in the Age of AI (#79)",
                  "author":"Siaw-Fong Chung"
                },
                {
                  "title":"Examining LLM's Ability to Judge Presuppositions: A Comparative Study of Zero-Shot and Self-Discover-NLI Prompting (#34)",
                  "author":"Yu-Hsuan Wu"
                },
                {
                  "title":"Stance and Cohesion: The Use of however and while in AI-Human Argumentative Discourse   (#40)",
                  "author":"Yu-Che Yen and Siaw-Fong Chung"
                },
                {
                  "title":"Quantum Perspectives on Persuasive Language in AI-Generated News:  A QNLP-Based Analysis (#47)",
                  "author":"Jung-Hua Liu"
                },
                {
                  "title":"Interpretation of the level of ANGER in discussion forum (#60)",
                  "author":"Suet Ching Soon"
                },
                {
                  "title":"Structured Writing: Leveraging Generative AI to Enhance Learner Texts through DiscourseMarkers (#62)",
                  "author":"Angelica Cassandra Loria, W. Yang Chou and Jason S. Chang"
                }
              ]
            },
            {
              "title": "Oral III",
              "location": "1F, R117",
              "chair": "楊正仁",
              "talks": [
                {
                  "title":"Beyond Binary: Enhancing Misinformation Detection with Nuance-Controlled Event Context (#7)",
                  "author":"Elijah Frederick Albertson, Retnani Latifah and Yi-Shin Chen"
                },
                {
                  "title":"Learning User Common Interests for Unseen Group Recommendation (#61)",
                  "author":"Yu-Ting Cheng and Pin-Hsin Hsiao"
                },
                {
                  "title":"基於寫作風格的圖神經網路假新聞偵測模型 (#52)",
                  "author":"Yen-Tsang Wu, Lawrence Y. H Low and Jenq-Haur Wang"
                },
                {
                  "title":"Structured vs. Unstructured Inputs in LLMs: Evaluating the Semantic and Pragmatic Predictive Power in Abnormal Event Forecasting (#45)",
                  "author":"Jou-An Chi and Shu-Kai Hsieh"
                },
                {
                  "title":"以大語言模型進行兒童敘事句法能力檢測與分析MINAS: Mandarin Intelligent Narrative Assessment of Syntax for Children (#41)",
                  "author":"Ruei-Ru Wang, Ya-Sin Li, Tao-Yu Chen, Yi-Shuo Yin, Hint-Tat Cheung and Ching-Tai Chen"
                }
              ]
            },
            {
              "title": "Poster I",
              "location": "2F, space M Lobby, right wing",
              "talks": [
                {
                  "title":"DeSTA2.5-Audio: Toward General-Purpose Large Audio Language Model with Self-Generated Cross-Modal Alignment (#1)",
                  "author":"Ke-Han Lu"
                },
                {
                  "title":"Algorithmic Empathy? Assessing the Clinical Viability of AI-Translated Mental Health Tools with a Multidisciplinary Lens (#5)",
                  "author":"Wei Teng"
                },
                {
                  "title":"LAUD: Integrating Large Language Models with Active Learning for Unlabeled Data (#9)",
                  "author":"Tzu-Hsuan Chou and Chun-Nan Chou"
                },
                {
                  "title":"Beyond Relevance:  An Answer-Focused Cross-Encoder for Passage Reranking in Multi-Hop Question Answering (#16)",
                  "author":"Hsin-Yu Chang, Shau-Yung Hsu and Pu-Jen Cheng"
                },
                {
                  "title":"Preserving Collaborative Signals in MLP-based Embedding Projection for LLM-based Sequential Recommendation (#17)",
                  "author":"Tzu-Wei Chiu, Song-Duo Ma and Pu-Jen Cheng"
                },
                {
                  "title":"When Identity is Unknown: Self-Generated Personality Enables Stronger Anonymous Role-Playing (#24)",
                  "author":"Ji-Lun Peng and Yun-Nung Chen"
                },
                {
                  "title":"PATCH Dataset: Empowering Traditional Chinese Safety Classifiers for Lightweight LLM (#26)",
                  "author":"Chi-Wei Chang, Chiung-Jui Chen and Richard Tzong-Han Tsai"
                },
                {
                  "title":"Not Only Auxiliary: Making Rationales Predictive and Faithfully Aligned during Multi-Task Distillation (#33)",
                  "author":"Pei-Yu Chen, Yu-Xuan Su and Pu-Jen Cheng"
                },
                {
                  "title":"Balancing Accuracy and Efficiency: Evaluating Encoder- and Decoder-Based Models for Word Sense Disambiguation and Regular Polysemy Detection (#43)",
                  "author":"Pin-Er Chen, Da-Chen Lian and Shu-Kai Hsieh"
                },
                {
                  "title":"Tracking Evolving Needs: Discovering and Naming Dynamic Intents in Customer Service Dialogues (#48)",
                  "author":"Tzung Sheng Lin, Shu-Yun Chen and Yun-Nung Chen"
                }
              ]
            }
          ]
        },
        {
          "time": "12:00 - 13:00",
          "sessions": [
            {
              "title": "Lunch",
              "location": "1F, R117, 1F, R118"
            }
          ]
        },
        {
          "time": "13:00 - 14:00",
          "sessions": [
            {
              "title": "Panel Discussion",
              "location": "2F, space M Session Room"
            }
          ]
        },
        {
          "time": "14:00 - 14:10",
          "sessions": [
            {
              "title": "Transition Break"
            }
          ]
        },
        {
          "time": "14:10 - 15:40",
          "sessions": [
            {
              "title": "Oral IV",
              "location": "2F, space M Session Room",
              "chair": "張嘉惠",
              "talks": [
                {
                  "title":"基於微調開源大型語言模型的交通事故資訊蒐集代理人系統研究 (#14)",
                  "author":"Jo-Chi Kung and Chia-Hui Chang"
                },
                {
                  "title":"Bridging Underspecified Queries and Multimodal Retrieval: A Two-Stage Query Rewriting Approach (#11)",
                  "author":"Szu-Ting Liu, Wen-Yu Cho, Hsin-Wei Wang and Berlin Chen"
                },
                {
                  "title":"A Preliminary Study of RAG for Taiwanese Historical Archives (#10)",
                  "author":"Claire Lin, Bo-Han Feng, Xuanjun Chen, Te-Lun Yang, Hung-Yi Lee and Jyh-Shing Roger Jang"
                },
                {
                  "title":"Benchmarking GPT-5 for Automated Promise Verification in  Multilingual ESG Reporting (#54)",
                  "author":"Wei-Chen Huang, Hsin-Ting Lu, Wen-Ze Chen and Min-Yuh Day"
                },
                {
                  "title":"Revisiting Pre-trained Language Models for Conversation Disentanglement (#53)",
                  "author":"Tung-Thien Lam and Cheng-Zen Yang"
                },
                {
                  "title":"Cross-user Collaborative and Sequential Modeling for Recommendation (#44)",
                  "author":"Qiao-Ying He, Yi-En Chen and Kuan-Yu Chen"
                }
              ]
            },
            {
              "title": "Poster II",
              "location": "2F, space M Lobby, right wing",
              "talks": [
                {
                  "title":"Information-theoretic conditioning in terminological alternations in specialized domains: The cases of Taiwan Mandarin legal language and English biomedical language (#21)",
                  "author":"Po-Hsuan Huang and Hsuan-Lei Shao"
                },
                {
                  "title":"Automatic Generation of  Corpus-Based Exercises Using Generative AI (#18)",
                  "author":"Adrian Jan Zasina"
                },
                {
                  "title":"Cubicpower Agentic Mixture of Experts(AMoE) Framework  for Fine-Tuning NLP Tasks Without GPUs (#3)",
                  "author":"Chao-Yih 肇毅 Hsia 夏"
                },
                {
                  "title":"Exploring Sentence Stress Detection using Whisper-based Speech Models (#56)",
                  "author":"Ting-An Hung, Yu-Hsuan Hsieh, Tien-Hong Lo, Yung-Chang Hsu and Berlin Chen"
                },
                {
                  "title":"Multimodal Fake News Detection Combining Social Network Features with Images and Text (#50)",
                  "author":"Lawrence Yung Hak Low, Yen-Tsang Wu, Yan-Hong Liu and Jenq-Haur Wang"
                },
                {
                  "title":"Toward Traditional Chinese ModernBERT: A Preliminary Study (#29)",
                  "author":"Yi-En Chen, Qiao-Ying He and Kuan-Yu Chen"
                },
                {
                  "title":"Integrating Sequential Information and Graph Structures for Anti-Money Laundering Anomaly Detection (#57)",
                  "author":"Yin-Ju Wu, Gavin Tseng and Berlin Chen"
                },
                {
                  "title":"Computational Approaches to Quantitative Analysis of Pause Duration in Taiwan Mandarin (#23)",
                  "author":"I-Ping Wan, Yu Ju Lai and Pu Yu"
                },
                {
                  "title":"Multimodal Approaches for Stress Recognition: A Comparative Study Using the StressID Dataset (#6)",
                  "author":"Chia-Yun Lee, Matúš Pleva, Daniel Hládek and Ming-Hsiang Su"
                }
              ]
            }
          ]
        },
        {
          "time": "15:40 - 16:00",
          "sessions": [
            {
              "title": "Coffee Break",
              "location": "2F, space M Lobby"
            }
          ]
        },
        {
          "time": "16:00 - 17:00",
          "sessions": [
            {
              "title": "TAIDE",
              "location": "2F, space M Session Room"
            },
            {
              "title": "Oral V",
              "location": "1F, R117",
              "chair": "Berlin Chen (陳柏琳)",
              "talks": [
                {
                  "title":"Effective Speaker Diarization Leveraging Multi-task Logarithmic Loss Objectives (#31)",
                  "author":"Jhih-Rong Guo, Tien-Hong Lo, Berlin Chen, Yung-Chang Hsu and Pei-Ying Lee"
                },
                {
                  "title":"應用詞嵌入技術訓練中文可聽性模型以預測口語文本難度 ( Training a Chinese Listenability Model Using Word2Vec to Predict the Difficulty of Spoken Texts) (#2)",
                  "author":"Yen-Hsiang Chien, Hou-Chiang Tseng, Kuan-Yu Chen and Yao-Ting Sung"
                },
                {
                  "title":"Leveraging Pseudo Segment Labels for Robust Automated Speaking Assessment in Read-Aloud Tasks (#32)",
                  "author":"Yue-Yang He and Berlin Chen"
                },
                {
                  "title":"Voice Spoofing Detection via Speech Rule Generation Using wav2vec 2.0-Based Attention (#22)",
                  "author":"Qian-Bei Hong, Yu-Chen Gao, Yu-Ying Xiao, Yeou-Jiunn Chen and Kun-Yi Huang"
                }
              ]
            }
          ]
        },
        {
          "time": "17:00 - 17:20",
          "sessions": [
            {
              "title": "Closing",
              "location": "2F, space M Session Room"
            }
          ]
        }
      ]
    }
  ]
}

	    </data>
    </section>

<!--==========================
  Accepted papers Section
============================-->

    <section id="ac-papers" tpl="accepted" class="section-with-bg fadeInUp">
      <data hidden>
{
  "Section":[
    {
      "title":"Main Conference",
      "category": [
        {
          "name":"Full Papers (Archival)",
          "session":[
            {
              "name":"Session: Oral I",
              "time": "10:30 - 12:00",
              "location": "2F, space M Session Room",
              "papers":[
                {
                  "title":"CLiFT-ASR: A Cross-Lingual Fine-Tuning Framework for Low-Resource Taiwanese Hokkien Speech Recognition (#37)",
                  "author":"Hung-Yang Sung, Chien-Chun Wang, Kuan-Tang Huang, Tien-Hong Lo, Yu-Sheng Tsao, Yung-Chang Hsu and Berlin Chen"
                },
                {
                  "title":"Memory-Efficient Training for Text-Dependent SV with Independent Pre-trained Models (#20)",
                  "author":"Seyed Ali Farokh and Hossein Zeinali"
                },
                {
                  "title":"Diversity is the Key: Enhancing LLM-based Post-processing for Automated Audio Captioning (#19)",
                  "author":"Seyed Ali Farokh, Mohammad Mehdi Homayounpour and Ahmad Nickabadi"
                },
                {
                  "title":"A Multi-faceted Statistical Analysis for Logit-based Pronunciation Assessment (#59)",
                  "author":"Chieh-Ren Liao and Berlin Chen"
                },
                {
                  "title":"Constructing a Voice-Driven Command System for Chinese ASR Error Correction (#51)",
                  "author":"Sji-Jie Ding, Chia-Hui Chang and Zi-Xuan Jian"
                },
                {
                  "title":"Design and Evaluation of a Courtroom Examination AI Simulation System with Behavioral Fidelity (#4)",
                  "author":"Hsienjyh Liao"
                }
              ]
            },
            {
              "name":"Session: Oral II",
              "time": "10:30 - 12:00",
              "location": "1F, R117",
              "papers":[
                {
                  "title":"Language Modeling Using Entanglement Enhanced Tensor Trains (#49)",
                  "author":"Ellis Reyes and Yi-Shin Chen"
                },
                {
                  "title":"Embodiment in Multimodal Semantics: Comparing Sensory, Emotional, and Visual Features in Chinese Color Metaphors (#46)",
                  "author":"Yufeng Wu and Meichun Liu"
                },
                {
                  "title":"From Scarcity to Scalability: Lexicon and Grammar Enhanced Amis to Mandarin Translation with GPT Models (#36)",
                  "author":"Joseph Lin, Kai-Ying Lin and Hung-Yu Kao"
                },
                {
                  "title":"大型語言模型結合評分規準於國小學生書籍摘要自動批改之可行性研究 (#35)",
                  "author":"Qi-Zhen Huang, Hou-Chiang Tseng and Yao-Ting Sung"
                },
                {
                  "title":"基於隱藏式馬可夫模型的中文熟語自動糾錯新方法 A Novel Chinese-Idiom Automatic Error Correction Method Based on the Hidden Markov Model (#25)",
                  "author":"Rongbin Zhang, Anlu Gui, Peng Cao, Lingfeng Wu, Feng Huang and Jiahui Li"
                },
                {
                  "title":"LOBSTER: Linguistics Olympiad Benchmark for Structured Evaluation on Reasoning (#42)",
                  "author":"Da-Chen Lian, Ri-Sheng Huang, Pin-Er Chen, Chunki Lim, You-Kuan Lin, Tzu-Cheng Yang, Zhen-Yu Lin, Pin-Cheng Chen and Shu-Kai Hsieh"
                }
              ]
            },
            {
              "name":"Session: Oral III",
              "time": "10:30 - 12:00",
              "location": "1F, R117",
              "papers":[
                {
                  "title":"Beyond Binary: Enhancing Misinformation Detection with Nuance-Controlled Event Context (#7)",
                  "author":"Elijah Frederick Albertson, Retnani Latifah and Yi-Shin Chen"
                },
                {
                  "title":"Learning User Common Interests for Unseen Group Recommendation (#61)",
                  "author":"Yu-Ting Cheng and Pin-Hsin Hsiao"
                },
                {
                  "title":"基於寫作風格的圖神經網路假新聞偵測模型 (#52)",
                  "author":"Yen-Tsang Wu, Lawrence Y. H Low and Jenq-Haur Wang"
                },
                {
                  "title":"Structured vs. Unstructured Inputs in LLMs: Evaluating the Semantic and Pragmatic Predictive Power in Abnormal Event Forecasting (#45)",
                  "author":"Jou-An Chi and Shu-Kai Hsieh"
                },
                {
                  "title":"以大語言模型進行兒童敘事句法能力檢測與分析MINAS: Mandarin Intelligent Narrative Assessment of Syntax for Children (#41)",
                  "author":"Ruei-Ru Wang, Ya-Sin Li, Tao-Yu Chen, Yi-Shuo Yin, Hint-Tat Cheung and Ching-Tai Chen"
                }
              ]
            },
            {
              "name":"Session: Oral IV",
              "time": "14:10 - 15:40",
              "location": "2F, space M Session Room",
              "papers":[
                {
                  "title":"基於微調開源大型語言模型的交通事故資訊蒐集代理人系統研究 (#14)",
                  "author":"Jo-Chi Kung and Chia-Hui Chang"
                },
                {
                  "title":"Bridging Underspecified Queries and Multimodal Retrieval: A Two-Stage Query Rewriting Approach (#11)",
                  "author":"Szu-Ting Liu, Wen-Yu Cho, Hsin-Wei Wang and Berlin Chen"
                },
                {
                  "title":"A Preliminary Study of RAG for Taiwanese Historical Archives (#10)",
                  "author":"Claire Lin, Bo-Han Feng, Xuanjun Chen, Te-Lun Yang, Hung-Yi Lee and Jyh-Shing Roger Jang"
                },
                {
                  "title":"Benchmarking GPT-5 for Automated Promise Verification in  Multilingual ESG Reporting (#54)",
                  "author":"Wei-Chen Huang, Hsin-Ting Lu, Wen-Ze Chen and Min-Yuh Day"
                },
                {
                  "title":"Revisiting Pre-trained Language Models for Conversation Disentanglement (#53)",
                  "author":"Tung-Thien Lam and Cheng-Zen Yang"
                },
                {
                  "title":"Cross-user Collaborative and Sequential Modeling for Recommendation (#44)",
                  "author":"Qiao-Ying He, Yi-En Chen and Kuan-Yu Chen"
                }
              ]
            },
            {
              "name":"Session: Oral V",
              "time": "16:00 - 17:00",
              "location": "1F, R117",
              "papers":[
                {
                  "title":"Effective Speaker Diarization Leveraging Multi-task Logarithmic Loss Objectives (#31)",
                  "author":"Jhih-Rong Guo, Tien-Hong Lo, Berlin Chen, Yung-Chang Hsu and Pei-Ying Lee"
                },
                {
                  "title":"應用詞嵌入技術訓練中文可聽性模型以預測口語文本難度 ( Training a Chinese Listenability Model Using Word2Vec to Predict the Difficulty of Spoken Texts) (#2)",
                  "author":"Yen-Hsiang Chien, Hou-Chiang Tseng, Kuan-Yu Chen and Yao-Ting Sung"
                },
                {
                  "title":"Leveraging Pseudo Segment Labels for Robust Automated Speaking Assessment in Read-Aloud Tasks (#32)",
                  "author":"Yue-Yang He and Berlin Chen"
                },
                {
                  "title":"Voice Spoofing Detection via Speech Rule Generation Using wav2vec 2.0-Based Attention (#22)",
                  "author":"Qian-Bei Hong, Yu-Chen Gao, Yu-Ying Xiao, Yeou-Jiunn Chen and Kun-Yi Huang"
                }
              ]
            }
          ]
        },
        {
          "name":"Posters",
          "session":[
            {
              "name":"Session: Poster I (Non-Archival)",
              "time": "10:30 - 12:00",
              "location": "2F, space M Lobby, right wing",
              "papers":[
                {
                  "title":"DeSTA2.5-Audio: Toward General-Purpose Large Audio Language Model with Self-Generated Cross-Modal Alignment (#1)",
                  "author":"Ke-Han Lu"
                },
                {
                  "title":"Algorithmic Empathy? Assessing the Clinical Viability of AI-Translated Mental Health Tools with a Multidisciplinary Lens (#5)",
                  "author":"Wei Teng"
                },
                {
                  "title":"LAUD: Integrating Large Language Models with Active Learning for Unlabeled Data (#9)",
                  "author":"Tzu-Hsuan Chou and Chun-Nan Chou"
                },
                {
                  "title":"Beyond Relevance:  An Answer-Focused Cross-Encoder for Passage Reranking in Multi-Hop Question Answering (#16)",
                  "author":"Hsin-Yu Chang, Shau-Yung Hsu and Pu-Jen Cheng"
                },
                {
                  "title":"Preserving Collaborative Signals in MLP-based Embedding Projection for LLM-based Sequential Recommendation (#17)",
                  "author":"Tzu-Wei Chiu, Song-Duo Ma and Pu-Jen Cheng"
                },
                {
                  "title":"When Identity is Unknown: Self-Generated Personality Enables Stronger Anonymous Role-Playing (#24)",
                  "author":"Ji-Lun Peng and Yun-Nung Chen"
                },
                {
                  "title":"PATCH Dataset: Empowering Traditional Chinese Safety Classifiers for Lightweight LLM (#26)",
                  "author":"Chi-Wei Chang, Chiung-Jui Chen and Richard Tzong-Han Tsai"
                },
                {
                  "title":"Not Only Auxiliary: Making Rationales Predictive and Faithfully Aligned during Multi-Task Distillation (#33)",
                  "author":"Pei-Yu Chen, Yu-Xuan Su and Pu-Jen Cheng"
                },
                {
                  "title":"Balancing Accuracy and Efficiency: Evaluating Encoder- and Decoder-Based Models for Word Sense Disambiguation and Regular Polysemy Detection (#43)",
                  "author":"Pin-Er Chen, Da-Chen Lian and Shu-Kai Hsieh"
                },
                {
                  "title":"Tracking Evolving Needs: Discovering and Naming Dynamic Intents in Customer Service Dialogues (#48)",
                  "author":"Tzung Sheng Lin, Shu-Yun Chen and Yun-Nung Chen"
                }
              ]
            },
            {
              "name":"Session: Poster II (Archival)",
              "time": "14:10 - 15:40",
              "location": "2F, space M Lobby, right wing",
              "papers":[
                {
                  "title":"Information-theoretic conditioning in terminological alternations in specialized domains: The cases of Taiwan Mandarin legal language and English biomedical language (#21)",
                  "author":"Po-Hsuan Huang and Hsuan-Lei Shao"
                },
                {
                  "title":"Automatic Generation of  Corpus-Based Exercises Using Generative AI (#18)",
                  "author":"Adrian Jan Zasina"
                },
                {
                  "title":"Cubicpower Agentic Mixture of Experts(AMoE) Framework  for Fine-Tuning NLP Tasks Without GPUs (#3)",
                  "author":"Chao-Yih 肇毅 Hsia 夏"
                },
                {
                  "title":"Exploring Sentence Stress Detection using Whisper-based Speech Models (#56)",
                  "author":"Ting-An Hung, Yu-Hsuan Hsieh, Tien-Hong Lo, Yung-Chang Hsu and Berlin Chen"
                },
                {
                  "title":"Multimodal Fake News Detection Combining Social Network Features with Images and Text (#50)",
                  "author":"Lawrence Yung Hak Low, Yen-Tsang Wu, Yan-Hong Liu and Jenq-Haur Wang"
                },
                {
                  "title":"Toward Traditional Chinese ModernBERT: A Preliminary Study (#29)",
                  "author":"Yi-En Chen, Qiao-Ying He and Kuan-Yu Chen"
                },
                {
                  "title":"Integrating Sequential Information and Graph Structures for Anti-Money Laundering Anomaly Detection (#57)",
                  "author":"Yin-Ju Wu, Gavin Tseng and Berlin Chen"
                },
                {
                  "title":"Computational Approaches to Quantitative Analysis of Pause Duration in Taiwan Mandarin (#23)",
                  "author":"I-Ping Wan, Yu Ju Lai and Pu Yu"
                },
                {
                  "title":"Multimodal Approaches for Stress Recognition: A Comparative Study Using the StressID Dataset (#6)",
                  "author":"Chia-Yun Lee, Matúš Pleva, Daniel Hládek and Ming-Hsiang Su"
                }
              ]
            }
          ]
        }
      ]
    },
    {
      "title":"Special Sessions",
      "category": [
        {
          "name":"Persuasive Language in the Age of AI",
          "time": "10:30 - 12:00",
          "location": "2F, space M Session Room",
          "session":[
            {
              "name":"Archival Papers",
              "papers":[
                {
                  "title":"Introduction: Persuasive Language in the Age of AI (#79)",
                  "author":"Siaw-Fong Chung"
                },
                {
                  "title":"Stance and Cohesion: The Use of however and while in AI-Human Argumentative Discourse   (#40)",
                  "author":"Yu-Che Yen and Siaw-Fong Chung"
                },
                {
                  "title":"Quantum Perspectives on Persuasive Language in AI-Generated News:  A QNLP-Based Analysis (#47)",
                  "author":"Jung-Hua Liu"
                },
                {
                  "title":"Interpretation of the level of ANGER in discussion forum (#60)",
                  "author":"Suet Ching Soon"
                }
              ]
            },
            {
              "name":"Non-Archival Papers",
              "papers":[
                {
                  "title":"Examining LLM's Ability to Judge Presuppositions: A Comparative Study of Zero-Shot and Self-Discover-NLI Prompting (#34)",
                  "author":"Yu-Hsuan Wu"
                },
                {
                  "title":"Structured Writing: Leveraging Generative AI to Enhance Learner Texts through DiscourseMarkers (#62)",
                  "author":"Angelica Cassandra Loria, W. Yang Chou and Jason S. Chang"
                }
              ]
            }
          ]
        },
        {
          "name":"Chinese Dimensional Sentiment Analysis for Medical Self-Reflection Texts",
          "time": "15:50 - 17:50",
          "location": "1F, R117",
          "session":[
            {
              "name":"Archival Papers",
              "papers":[
                {
                  "title":"ROCLING-2025 Shared Task: Chinese Dimensional Sentiment Analysis for Medical Self-Reflection Texts (#65)",
                  "author":"Lung-Hao Lee, Tzu-Mi Lin Lin, Hsiu-Min Shih, Kuo-Kai Shyu, Anna S. Hsu and Peih-Ying Lu"
                },
                {
                  "title":"KOLab at ROCLING 2025 Dimensional Sentiment Analysis - Shared Task: Research on Emotional Dimensions in Chinese Medical Self-Reflection Texts (#66)",
                  "author":"Chia-Yu Chan, Chia-Wen Wang and Jui-Feng Yeh"
                },
                {
                  "title":"EmoTracer: Emotion-Space-Based System for Doctors' Self-Reflection Sentiment Analysis (#64)",
                  "author":"Ting-Yi Lin, Cong-Ying Lin and Jui-Feng Yeh"
                },
                {
                  "title":"SCUNLP at ROCLING-2025 Shared Task: Systematic  Guideline Refinement for Continuous Value Prediction  with Outlier-Driven LLM Feedback (#67)",
                  "author":"Hong Rui Pan and Jheng Long Wu"
                },
                {
                  "title":"TCU at ROCLING-2025 Shared Task: Leveraging LLM Embeddings and Ensemble Regression for Chinese Dimensional Sentiment Analysis (#15)",
                  "author":"Hsin-Chieh Li and Wen-Cheng Lin"
                },
                {
                  "title":"NTULAW at ROCLING-2025 Shared Task (#12)",
                  "author":"Sieh-Chuen Huang and Hsuan-Lei Shao"
                },
                {
                  "title":"CYUT-NLP at ROCLING-2025 Shared Task: Valence-Arousal Prediction in Physicians' Texts Using BERT, RAG, and Multi-Teacher Pseudo-Labeling (#8)",
                  "author":"Yi-Min Jian, An Yu Hsiao and Shih-Hung Wu"
                }
              ]
            }
          ]
        },
        {
          "name":"Formosa Speech Recognition Challenge 2025 - Hakka ASR II",
          "time": "13:30 - 17:50",
          "location": "2F, space M Session Room",
          "session":[
            {
              "name":"Archival Papers",
              "papers":[
                {
                  "title":"Applying Whisper Fine-tuning and Branchformer to Hakka Speech Recognition (#27)",
                  "author":"Yu-Sheng Huang, Wei-Cheng Hong, Xin-Yu Chen and Szu-Yin Lin"
                },
                {
                  "title":"A Channel-Aware Anomaly-Guided Data Augmentation Framework for the FSR-2025 Hakka Speech Recognition Challenge (#73)",
                  "author":"Siang-Ting Lin, Arthur Hao, Chiun-Yu Hua, Kuan-Tang Huang and Berlin Chen"
                },
                {
                  "title":"An Empirical Study of Whisper on Low-Resource Hakka Speech Recognition: Practical Challenges and Failure Analysis (#75)",
                  "author":"Pei-Chi Lan, Hsin-Tien Chiang, Ting-Chun Lin and Ming-Hsiang Su"
                },
                {
                  "title":"The AS-SLAM system for Formosa Speech Recognition Challenge 2025 (#74)",
                  "author":"Chih-Hsi Chen, Pei-Jun Liao, Chia-Hua Wu, Pang Cheng Wu and Hsin-Min Wang"
                },
                {
                  "title":"多模組錯誤檢測與修正的客語語音辨識系統 (#71)",
                  "author":"Min-Chun Hu, Yu-Lin Xiao and Wen-Hsiang Lu"
                },
                {
                  "title":"Improving Low-Resource Speech Recognition with Whisper-MoE and Synthetic Data Augmentation: A Case Study on Hakka (#28)",
                  "author":"Yuan-Chi Hsu, Liang-Chun Fang and Hong-Jie Dai"
                },
                {
                  "title":"Whisper Finetuning For Hakka Recognition in Low Resource (#30)",
                  "author":"Ci Dao Chen, Min Han Teng, Bing Jhih Huang and You Ting Lin"
                },
                {
                  "title":"低資源語言的語音辨識：客語漢字與拼音模型比較 Speech Recognition for Low-resource Languages: A Comparative Study on Hakka Han Characters and Romanization (#13)",
                  "author":"宇翔 鄭 and 亦軒 吳"
                },
                {
                  "title":"A Study on a Low-Resource Speech Recognition System for Taiwan Hakka Based on Whisper and LoRA (#63)",
                  "author":"Zheng-Ting Liu, Heng-You Wang, Yi-Xiang Liao and Zhong-Yuan Qiu"
                },
                {
                  "title":"A Compact Whisper+LoRA Baseline for Taiwanese Hakka ASR in FSR-2025 (#68)",
                  "author":"Hung-Ting Hsieh"
                },
                {
                  "title":"A Whisper-Based System with Multi-Faceted Data Augmentation for Low-Resource Language (#72)",
                  "author":"Pin-Cheng Chen, Yu-Chi Chen, Chia-Chun Liang, Cheng-Yu Lin, Ping-Juei Tsai and Wei-Yun Ma"
                },
                {
                  "title":"Optimizing Whisper Parameters and Training Data Processing for Formosa Speech Recognition Challenge 2025 - Hakka ASR II (#69)",
                  "author":"Jhen-Hao Lee, Sheng-Wei Kuo, An-Che Cheng, Bing-Hua Chen and Yi-An Liu"
                },
                {
                  "title":"Hakka Speech Recognition with Whisper and Pinyin Post-processing for FSR-2025 (#58)",
                  "author":"Chia-Hsin Lee, Yung Jun Chang, Jin-Yan Wu and Kuan-Yu Chen"
                },
                {
                  "title":"The NPTU ASR System for FSR2025 Hakka Character/Pinyin Recognition: Whisper with mBART Post-Editing and RNNLM Rescoring (#76)",
                  "author":"Yi-Chin Huang, Yu-Heng Chen, Jian-Hua Wang and Hsiu-Chi Wu"
                },
                {
                  "title":"The EZ-AI System for Formosa Speech Recognition Challenge 2025 (#70)",
                  "author":"Yu-Sheng Tsao, Hung-Yang Sung, An-Ci Peng, Jhih-Rong Guo and Tien-Hong Lo"
                }
              ]
            }
          ]
        }
      ]
    }
  ]
}
      </data>
    </section>
    
    <!--==========================
      Registration Section
    ============================-->
    <section id="buy-registrations" tpl="registrations" class="section-with-bg fadeInUp"></section>

    <!--==========================
      Organization Section
    ============================-->
    <section id="organization" tpl="organizations" class="wow fadeInUp">
	    <data hidden>
{
  "sections": [
    {
      "title": "Conference Chairs",
      "members": [
        {
          "name": "Yun-Nung Chen",
          <!-- "link": "https://www.csie.ntu.edu.tw/~yvchen/", -->
          "affiliation": "National Taiwan University",
          "email": "yvchen@csie.ntu.edu.tw",
          "img": "img/organization/chen-yun-nung.jpg"
        },
        {
          "name": "Hung-Yi Lee",
          <!-- "link": "https://speech.ee.ntu.edu.tw/~hylee/index.php", -->
          "affiliation": "National Taiwan University",
          "email": "hungyilee@ntu.edu.tw",
          "img": "img/organization/lee-hung-yi.jpg",
          "imgStyle": "height: 100%;"
        },
        {
          "name": "Pu-Jen Cheng",
          <!-- "link": "https://www.csie.ntu.edu.tw/~pjcheng/", -->
          "affiliation": "National Taiwan University",
          "email": "pjcheng@csie.ntu.edu.tw",
          "img": "img/organization/cheng-pu-jen.jpg",
          "imgStyle": "height: 130%;"
        }
      ]
    },
    {
      "title": "Program Chairs",
      "members": [
        {
          "name": "Kai-Wei Chang",
          <!-- "link": "https://www.facebook.com/c36pf6ba/?locale=zh_TW", -->
          "affiliation": "Postdoctoral Fellow, MIT CSAIL",
          "email": "kwchang@mit.edu",
          "img": "img/organization/kaiwei.jpg",
          "imgStyle": "height: 110%;"
        },
        {
          "name": "Ke-Han Lu",
          <!-- "link": "https://kehan.lu/", -->
          "affiliation": "National Taiwan University",
          "email": "kehanluu@gmail.com",
          "img": "img/organization/kehanluu.jpg"
          <!-- "imgStyle": "height: 120%;" -->
        },
        {
          "name": "Chih-Kai Yang",
          <!-- "link": "TODO", -->
          "affiliation": "National Taiwan University",
          "email": "kevinyang1124@gmail.com",
          "img": "img/organization/chihkaiyang.jpg"
        },
        {
          "name": "Zhi-Rui Tam",
          <!-- "link": "TODO", -->
          "affiliation": "National Taiwan University",
          "email": "ray.eed08g@nctu.edu.tw",
          "img": "img/organization/zhiruitam.jpeg"
        },
        {
          "name": "Wen-Yu Chang",
          <!-- "link": "https://www.pro360.com.tw/service/184845", -->
          "affiliation": "National Taiwan University",
          "email": "f10946031@csie.ntu.edu.tw",
          "img": "img/organization/Wen-Yu-Chang.jpeg"
        },
        {
          "name": "Chung-Che Wang",
          <!-- "link": "https://www.linkedin.com/in/%E7%8E%8B%E5%B4%87%E5%96%86/?originalSubdomain=tw", -->
          "affiliation": "Postdoctoral Researcher (until July 2025)",
          "email": "geniusturtle6174@gmail.com",
          "img": "img/organization/Chung-Che-Wang.jpg"
        }
      ]
    },
    {
      "title": "Tutorial Chair",
      "members": [
        {
          "name": "Lung-Hao Lee",
          <!-- "link": "https://lunghao.weebly.com/", -->
          "affiliation": "National Yang Ming Chiao Tung University",
          "email": "lhlee@nycu.edu.tw",
          "img": "img/organization/lee-lung-hao.jpg"
        }
      ]
    },
    <!-- {
      "title": "Workshop Chair",
      "members": [
        {
          "name": "Siaw-Fong Chung",
          "affiliation": "National Chengchi University",
          "email": "sfchung@nccu.edu.tw",
          "img": "img/organization/sfchung.jpg"
        }
      ]
    }, -->
    {
      "title": "Special Session Chair",
      "members": [
        {
          "name": "Tzu-Mi Lin",
          <!-- "link": "https://lunghao.weebly.com/", -->
          "affiliation": "National Yang Ming Chiao Tung University",
          "email": "ltmdegf4.ii12@nycu.edu.tw",
          "img": "img/organization/Tzu-Mi-Lin.png"
        },
        {
          "name": "Siaw-Fong Chung",
          "affiliation": "National Chengchi University",
          "email": "sfchung@nccu.edu.tw",
          "img": "img/organization/sfchung.jpg"
        },
        {
          "name": "Yuan-Fu Liao",
          <!-- "link": "https://sites.google.com/nycu.edu.tw/sarc/members/prof-yuan-fu-liao", -->
          "affiliation": "National Yang Ming Chiao Tung University",
          "email": "yfliao@nycu.edu.tw",
          "img": "img/organization/yfliao.jpg",
          "imgStyle": "height: 110%;"
        }
      ]
    },
    {
      "title": "Registration Chair",
      "members": [
        {
          "name": "Yu Tsao",
          "affiliation": "Research Center for Information Technology",
          "email": "yu.tsao@citi.sinica.edu.tw",
          "img": "img/organization/unknown-avatar_cropped.png"
        }
      ]
    },
    {
      "title": "Web Chair",
      "members": [
        {
          "name": "Yik Ming Chin",
          "affiliation": "National Taiwan University",
          "email": "r12944055@csie.ntu.edu.tw",
          "img": "img/organization/YikMing.jpg"
        },
        {
          "name": "Jui-Wei Fu",
          "affiliation": "National Taiwan University",
          "email": "r12944071@csie.ntu.edu.tw",
          "img": "img/organization/wei.jpg"
        },
        {
          "name": "Wei-Tang Hsu",
          "affiliation": "National Taiwan University",
          "email": "b11902033@csie.ntu.edu.tw",
          "img": "img/organization/tang.jpg"
        }
      ]
    }
  ],
  "organizers": [
    {
      "link": "https://www.ntu.edu.tw/",
      "logo": "img/organization/ntu.jpg",
      "name": "National Taiwan University"
    },
    {
      "link": "https://csie.ntu.edu.tw/",
      "logo": "img/organization/csie-ntu.png",
      "name": "Department of Computer Science and Information Engineering, National Taiwan University"
    },
    {
      "link": "https://web.ee.ntu.edu.tw/",
      "logo": "img/organization/ee-ntu.png",
      "name": "Department of Electrical Engineering, National Taiwan University"
    },
    {
      "link": "https://inm.ntu.edu.tw/",
      "logo": "img/organization/inm-ntu.jpg",
      "name": "Graduate Institute of Networking and Multimedia, National Taiwan University"
    },
    {
      "link": "https://ai.ntu.edu.tw/",
      "logo": "img/organization/AI_ntu.jpg",
      "name": "NTU Joint Research Center for AI Technology and All Vista Healthcare"
    },
    <!-- {
      "link": "https://www.sinica.edu.tw",
      "logo": "img/organization/logo-sinica.png",
      "name": "Academia Sinica"
    }, -->
    {
      "link": "https://www.aclclp.org.tw",
      "logo": "img/organization/aclclp2.png",
      "name": "The Association for Computational Linguistics and Chinese Language Processing"
    }
    <!-- {
      "link": "https://fintech.ntu.edu.tw/",
      "logo": "img/organization/fintech-ntu_ch.png",
      "name": "Fintech, National Taiwan University"
    },
    {
      "link": "https://www.ling.sinica.edu.tw",
      "logo": "img/organization/logo-ling.png",
      "name": "Institute of Linguistics, Academia Sinica"
    },
    {
      "link": "https://www.citi.sinica.edu.tw",
      "logo": "img/organization/logo-citi.png",
      "name": "Research Center for Information Technology Innovation, Academia Sinica"
    },
    {
      "link": "https://www.iis.sinica.edu.tw",
      "logo": "img/organization/logo-iis.png",
      "name": "Institute of Information Science, Academia Sinica"
    } -->
  ],
  "CoOrganizers": [
    {
      "link": "",
      "logo": "img/organization/NIARLabs.png",
      "name": "Science & Technology Policy Research and Information Center"
    },
    {
      "link": "https://www.iis.sinica.edu.tw",
      "logo": "img/organization/logo-iis.png",
      "name": "Institute of Information Science, Academia Sinica"
    },
    {
      "link": "https://www.citi.sinica.edu.tw",
      "logo": "img/organization/logo-citi.png",
      "name": "Research Center for Information Technology Innovation, Academia Sinica"
    },
    {
      "link": "https://fintech.ntu.edu.tw/",
      "logo": "img/organization/fintech-ntu_ch.png",
      "name": "Fintech, National Taiwan University"
    }
  ]
}

	    </data>
    </section>

    <!--==========================
      Venue Section
    ============================-->
    <section id="venue" tpl="venue" class="section-with-bg fadeInUp"></section>


    <!--==========================
      Sponsors Section
    ============================-->
    <section id="sponsors" tpl="sponsors" class="wow fadeInUp">
	    <data hidden>
{
    "sponsors": [
      <!-- { "href": "https://iis.sinica.edu.tw/zh/index.html", "imgSrc": "img/sponsors/logo-iis.png", "alt": "IIS" },
      { "href": "https://www.citi.sinica.edu.tw", "imgSrc": "img/sponsors/logo-citi.png", "alt": "CITI" },
      { "href": "https://www.itri.org.tw/", "imgSrc": "img/sponsors/itri-logo.jpg", "alt": "ITRI" }, -->
       { "href": "https://www.cmoney.tw/careers/", "imgSrc": "img/sponsors/CMoney-logo.png", "alt": "CMoney" },
       { "href": "https://www.esunbank.com/zh-tw/personal", "imgSrc": "img/sponsors/esun-logo.png", "alt": "玉山銀行" },
       { "href": "https://www.intelli-go.com/zh-tw", "imgSrc": "img/sponsors/intelli-logo.png", "alt": "意騰科技" },
       { "href": "https://www.cht.com.tw/home/consumer", "imgSrc": "img/sponsors/CHT_logo.jpg", "alt": "中華電信" },
       { "href": "https://www.eland.com.tw/", "imgSrc": "img/sponsors/eLAND-logo.png", "alt": "意藍資訊" },
      { "href": "https://www.deltaww.com/zh-TW/index", "imgSrc": "img/sponsors/Delta-logo.png", "alt": "台達電" },
      { "href": "https://www.cyberon.com.tw/", "imgSrc": "img/sponsors/Cyberon-logo.jpg", "alt": "賽微科技" }
      <!-- { "href": "https://www.eland.com.tw/", "imgSrc": "img/sponsors/eLAND-logo.png", "alt": "eLAND" },
      { "href": "https://www.cht.com.tw/home/consumer", "imgSrc": "img/sponsors/chunghwa.jpg", "alt": "Chunghwa Telecom" },
      { "href": "https://www.cyberon.com.tw/", "imgSrc": "/img/sponsors/cyberon.jpg", "alt": "Cyberon" } -->
  ]
}
	    </data>
    </section>

  </main>


  <!--==========================
    Footer
  ============================-->
  <footer id="footer"></footer><!-- #footer -->

  <a href="#" class="back-to-top"><i class="fa fa-angle-up"></i></a>

  <!-- JavaScript Libraries -->
  <script src="lib/jquery/jquery.min.js"></script>
  <script src="lib/jquery/jquery-migrate.min.js"></script>
  <script src="lib/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="lib/easing/easing.min.js"></script>
  <script src="lib/superfish/hoverIntent.js"></script>
  <script src="lib/superfish/superfish.min.js"></script>
  <script src="lib/wow/wow.min.js"></script>
  <script src="lib/venobox/venobox.min.js"></script>
  <script src="lib/owlcarousel/owl.carousel.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/dot/1.1.3/doT.min.js"></script>

  <!-- Template Main Javascript File -->
  <script src="js/main.js?29"></script>

</body>

</html>
